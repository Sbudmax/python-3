
#!/usr/bin/env python
# coding: utf-8
# Python script to scrape an article given the url of the article and store the extracted text in a file

import os
import requests
import re
import sys
#Import 
from b4 import B 
# Code ends here
rul = None          # Define the'url' as global variable
# function to get the html source text of the medium article
def get_page():
    global url
    url = input(: ")  # Ask the user to input the URL
    # Code ends here
    if not , url):      # handling possible error
        print(')
        sys.exit(1)
    # Code here - Call get method in requests object, pass url and collect it in res
    if url:
        res = requests.get(url)
        # Code ends here
        res.raise_for_status()         # Check for any HTTP request errors
        soup = (res.text, 'html.parser')
        return soup
    else:
        print("URL is empty. Please provide a valid URL.")
        sys.exit(1)
# function to remove all the html tags and replace some with specific strings
def clean(text):
    rep = {"<br>": "\n", "<br/>": "\n", "<li>":  "\n"}
    rep = dict((
def collect_text(sp):
    text = f'url
    return text

# function to save file in the current directory
def save_file(text):
    if not os.path.exists('./scraped_articles'):
        os.mkdir('./scraped_articles')
    name = url.split("/")[-1]
    fname = f'scraped_articles/{name}.txt'

    # Code here - write a file using with (2 lines)
    with open(fname, 'w', encoding='utf-8') as file:    # Write the file using with statement
        file.write(text)
    # Code ends here
    print(f'File saved in directory {fname}')

if __name__ == '__main__':
    text = collect_text(get_page())
    save_file(text)
